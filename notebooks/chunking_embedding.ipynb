{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9361740",
   "metadata": {},
   "source": [
    "### Chunking & Embedding: Transcript Preparation for YouTube QA Bot\n",
    "This notebook processes the transcript of a YouTube video into chunks, adds metadata, and stores them in a vector database using FAISS for semantic search.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5647756e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18cb002",
   "metadata": {},
   "source": [
    "### Load Transcript Text File\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "564af050",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.chunking import load_transcript\n",
    "transcript_path = \"../data/eleo_transcript.txt\"\n",
    "transcript_text = load_transcript(transcript_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b8c328",
   "metadata": {},
   "source": [
    "### Split Transcript into Chunks with Overlap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96985a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.chunking import split_into_chunks\n",
    "chunks = split_into_chunks(transcript_text, chunk_size=500, chunk_overlap=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2a6f5e",
   "metadata": {},
   "source": [
    "### Add Metadata to Each Chunk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3c33a3",
   "metadata": {},
   "source": [
    "Extract general metadata before adding to a chunk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2797ab07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube:tab] Unable to recognize playlist. Downloading just video SN-vBnWj6e8\n"
     ]
    }
   ],
   "source": [
    "#from utils.metadata_extract import extract_youtube_metadata\n",
    "#youtube_url = \"https://www.youtube.com/watch?v=SN-vBnWj6e8&list=PPSV\"\n",
    "#meta = extract_youtube_metadata(youtube_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c730c95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.chunking import add_chunk_metadata\n",
    "\n",
    "video_id = \"eleo_video_001\"\n",
    "transcript_title = \"Eleo YouTube Video\"\n",
    "author = \"Eleo Channel\"\n",
    "tags = [\"YouTube\", \"AI\", \"Transcript\"]\n",
    "\n",
    "chunk_docs = add_chunk_metadata(chunks, video_id, transcript_title, author, tags)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75305df8",
   "metadata": {},
   "source": [
    "### Save Chunked Data with Metadata as JSON\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48ed3c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.chunking import save_chunks_to_json\n",
    "output_path = \"../data/eleo_transcript_chunks.json\"\n",
    "save_chunks_to_json(chunk_docs, output_path)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f9f1db",
   "metadata": {},
   "source": [
    "### Save chunks to Langchain document\n",
    "Wraping each chunk in a `Document` object with metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bebf83ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.embedding import convert_to_documents\n",
    "documents = convert_to_documents(chunk_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5f9eb3",
   "metadata": {},
   "source": [
    "### Embed Chunks and Save to FAISS Vector Store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "031afe45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adriannadziadyk/Multimodal-AI-YouTube-QA-Bot/notebooks/../utils/embedding.py:15: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embedding_model = OpenAIEmbeddings(model=model)\n"
     ]
    }
   ],
   "source": [
    "from utils.embedding import embed_documents_with_openai, save_vectorstore_faiss\n",
    "faiss_index = embed_documents_with_openai(documents, model=\"text-embedding-3-small\")\n",
    "save_vectorstore_faiss(faiss_index, \"../data/vectorstores/eleo_faiss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91b85938",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.embedding import load_vectorstore_faiss\n",
    "faiss_index = load_vectorstore_faiss(\"../data/vectorstores/eleo_faiss\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
