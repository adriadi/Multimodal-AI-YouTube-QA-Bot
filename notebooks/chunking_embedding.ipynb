{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9361740",
   "metadata": {},
   "source": [
    "### Chunking & Embedding: Transcript Preparation for YouTube QA Bot\n",
    "This notebook processes the transcript of a YouTube video into chunks, adds metadata, and stores them in a vector database using FAISS for semantic search.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18cb002",
   "metadata": {},
   "source": [
    "### Load Transcript Text File\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564af050",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "with open(\"../data/eleo_transcript.txt\", \"r\") as f:\n",
    "    transcript_text = f.read()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b8c328",
   "metadata": {},
   "source": [
    "### Split Transcript into Chunks with Overlap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96985a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split chunks\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "chunks = splitter.split_text(transcript_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2a6f5e",
   "metadata": {},
   "source": [
    "### Add Metadata to Each Chunk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c730c95d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Created 26 chunks.\n"
     ]
    }
   ],
   "source": [
    "# Define the video_id for metadata\n",
    "video_id = \"eleo_video_001\"\n",
    "\n",
    "# Add metadata\n",
    "chunk_docs = []\n",
    "for i, chunk in enumerate(chunks):\n",
    "    chunk_docs.append({\n",
    "        \"content\": chunk,\n",
    "        \"metadata\": {\n",
    "            \"video_id\": video_id,\n",
    "            \"chunk_index\": i,\n",
    "            \"source\": \"Eleo's Corner\"\n",
    "        }\n",
    "    })\n",
    "\n",
    "print(f\"✅ Created {len(chunks)} chunks.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75305df8",
   "metadata": {},
   "source": [
    "### Save Chunked Data with Metadata as JSON\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "48ed3c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Chunks saved to ../data/chunks/eleo_chunks_meta.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# Save to chunks file\n",
    "os.makedirs(\"../data/chunks\", exist_ok=True)\n",
    "with open(\"../data/chunks/eleo_chunks_meta.json\", \"w\") as f:\n",
    "    json.dump(chunk_docs, f, indent=2)\n",
    "\n",
    "\n",
    "print(\"✅ Chunks saved to ../data/chunks/eleo_chunks_meta.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5f9eb3",
   "metadata": {},
   "source": [
    "### Embed Chunks and Save to FAISS Vector Store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0978be68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Chunks embedded and saved to FAISS at: ../data/vectorstores/eleo_faiss\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.schema import Document\n",
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load API key\n",
    "load_dotenv()\n",
    "\n",
    "# Convert chunks into LangChain Document objects (required format)\n",
    "documents = [\n",
    "    Document(page_content=chunk[\"content\"], metadata=chunk[\"metadata\"])\n",
    "    for chunk in chunk_docs\n",
    "]\n",
    "\n",
    "# Set up the OpenAI Embedding model\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# Save it locally so you can reuse it later\n",
    "os.makedirs(\"../data/vectorstores\", exist_ok=True)\n",
    "db.save_local(\"../data/vectorstores/eleo_faiss\")\n",
    "\n",
    "print(\"✅ Chunks embedded and saved to FAISS at: ../data/vectorstores/eleo_faiss\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
