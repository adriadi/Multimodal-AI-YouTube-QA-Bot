{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eac5c4d0",
   "metadata": {},
   "source": [
    "## Import Dependencies and Tools\n",
    "This section loads necessary libraries and adds the utils folder to the import path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "617df7ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Vectorstore not found at /Users/adriannadziadyk/Multimodal-AI-YouTube-QA-Bot/data/vectorstores/eleo_faiss/index.faiss. Run chunking + embedding pipeline first.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdocument_loaders\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TextLoader\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mwhisper_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m whisper_tool\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01magents\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlangchain_agent\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m agent_with_memory\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Multimodal-AI-YouTube-QA-Bot/notebooks/../agents/langchain_agent.py:22\u001b[39m\n\u001b[32m     20\u001b[39m index_path = os.path.join(vectorstore_path, \u001b[33m\"\u001b[39m\u001b[33mindex.faiss\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.exists(index_path):\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mVectorstore not found at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Run chunking + embedding pipeline first.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     24\u001b[39m db = FAISS.load_local(vectorstore_path, OpenAIEmbeddings(), allow_dangerous_deserialization=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     25\u001b[39m retriever = db.as_retriever()\n",
      "\u001b[31mFileNotFoundError\u001b[39m: Vectorstore not found at /Users/adriannadziadyk/Multimodal-AI-YouTube-QA-Bot/data/vectorstores/eleo_faiss/index.faiss. Run chunking + embedding pipeline first."
     ]
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import os\n",
    "\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.tools import Tool\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.document_loaders import TextLoader\n",
    "from utils.whisper_utils import whisper_tool\n",
    "from agents.langchain_agent import agent_with_memory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aecb876",
   "metadata": {},
   "source": [
    "## Load Vectorstore and Build Retriever\n",
    "Load the FAISS vector store to enable transcript-based question answering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5684419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use current working directory since __file__ is not defined in notebooks\n",
    "project_root = os.getcwd()\n",
    "video_id = \"SN-vBnWj6e8\"\n",
    "vectorstore_path = f\"../data/vectorstores/{video_id}_faiss\"\n",
    "\n",
    "\n",
    "db = FAISS.load_local(vectorstore_path, OpenAIEmbeddings(), allow_dangerous_deserialization=True)\n",
    "\n",
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d900c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for FAISS files in: /Users/adriannadziadyk/Multimodal-AI-YouTube-QA-Bot/data/vectorstores/eleo_faiss\n",
      "Found files: ['index.faiss', 'index.pkl']\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "print(\"Looking for FAISS files in:\", os.path.abspath(vectorstore_path))\n",
    "print(\"Found files:\", os.listdir(vectorstore_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6932ee",
   "metadata": {},
   "source": [
    "## Define Custom Prompt Template\n",
    "Create a custom prompt to ensure the agent only answers using transcript content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394ef87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "custom_prompt = PromptTemplate.from_template(\n",
    "    template=\"\"\"\n",
    "You are an assistant that answers questions only using the following transcript chunk.\n",
    "If the answer is not contained within it, reply with \"I don't know.\"\n",
    "\n",
    "Transcript:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7b12ca",
   "metadata": {},
   "source": [
    "## Create Retrieval QA Chain\n",
    "Build a chain that uses the retriever and custom prompt for context-aware answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244edee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=ChatOpenAI(model=\"gpt-3.5-turbo\"),\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs={\"prompt\": custom_prompt},\n",
    "    return_source_documents=False\n",
    ")\n",
    "\n",
    "def answer_question_only_result(query: str) -> str:\n",
    "    return qa_chain.invoke({\"query\": query})[\"result\"]\n",
    "\n",
    "qa_tool = Tool(\n",
    "    name=\"VideoQA\",\n",
    "    func=answer_question_only_result,\n",
    "    description=\"Answers questions about the Eleo German learning video\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93b0dbc",
   "metadata": {},
   "source": [
    "## Initialize Tools and LLM\n",
    "Combine QA and Whisper tools to equip the agent for multimodal tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d988ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [qa_tool, whisper_tool]\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bb29a4",
   "metadata": {},
   "source": [
    "## LangSmith Tracing Setup\n",
    "Define a tracked function for LangSmith monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e61803",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import traceable\n",
    "\n",
    "@traceable(name=\"Eleo_QA_Session\")\n",
    "def ask_agent_traced(question: str):\n",
    "    return agent_with_memory.run(question)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd8c00c",
   "metadata": {},
   "source": [
    "## Run Test Questions\n",
    "Example usage to validate that the system answers accurately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501a5ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m8/k1bt27ks3h3cd9920twfctb40000gn/T/ipykernel_90337/3644087192.py:5: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  return agent_with_memory.run(question)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
      "Action: VideoQA\n",
      "Action Input: How does Eleo recommend practicing German pronunciation?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mEleo recommends practicing German pronunciation by reading and listening to German texts.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mDo I need to use a tool? No\n",
      "AI: Eleo recommends practicing German pronunciation by reading and listening to German texts. This can help you improve your pronunciation by getting familiar with the sounds and rhythm of the language.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Eleo recommends practicing German pronunciation by reading and listening to German texts. This can help you improve your pronunciation by getting familiar with the sounds and rhythm of the language.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n",
      "AI: Eleo recommends practicing German pronunciation by reading and listening to German texts. This can help you improve your pronunciation by getting familiar with the sounds and rhythm of the language. Just practice reading and listening to German to work on your pronunciation.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Eleo recommends practicing German pronunciation by reading and listening to German texts. This can help you improve your pronunciation by getting familiar with the sounds and rhythm of the language. Just practice reading and listening to German to work on your pronunciation.\n"
     ]
    }
   ],
   "source": [
    "response_1 = ask_agent_traced(\"How does Eleo recommend practicing German pronunciation?\")\n",
    "print(response_1)\n",
    "\n",
    "response_2 = ask_agent_traced(\"Can you explain that again more simply?\")\n",
    "print(response_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52efaa7",
   "metadata": {},
   "source": [
    "###  LangChain RetrievalQA setup\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe80a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agent initialisation code\n",
    "agent_executor = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae552a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n",
      "AI: \"Guten Tag\" is a German greeting that means \"Good day\" in English. It is commonly used as a way to say hello or good afternoon in German.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\"Guten Tag\" is a German greeting that means \"Good day\" in English. It is commonly used as a way to say hello or good afternoon in German.\n"
     ]
    }
   ],
   "source": [
    "response = agent_executor.run(\"What does 'Guten Tag' mean?\")\n",
    "print(response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
