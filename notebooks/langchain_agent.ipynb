{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbb79e4f",
   "metadata": {},
   "source": [
    "### LangChain Agent Setup for YouTube QA Bot\n",
    "This notebook creates a LangChain agent that can answer questions based on the Eleo German learning video transcript using FAISS and OpenAI.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0728ea25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import Tool\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import RetrievalQA\n",
    "from langsmith import traceable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3be9f956",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "# Load FAISS vector store\n",
    "db = FAISS.load_local(\n",
    "    folder_path=\"../data/vectorstores/eleo_faiss\",\n",
    "    embeddings=OpenAIEmbeddings(model=\"text-embedding-3-small\"),\n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "retriever = db.as_retriever()\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=ChatOpenAI(model=\"gpt-3.5-turbo\"),\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9361740",
   "metadata": {},
   "source": [
    "###  Wrap QA Chain as a LangChain Tool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7447dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question_only_result(query: str) -> str:\n",
    "    return qa_chain.invoke({\"query\": query})[\"result\"]\n",
    "\n",
    "qa_tool = Tool(\n",
    "    name=\"VideoQA\",\n",
    "    func=answer_question_only_result,\n",
    "    description=\"Answers questions about the Eleo German learning video\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae44cdb",
   "metadata": {},
   "source": [
    "### Create Zero-Shot Agent (No Memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82e27320",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m8/k1bt27ks3h3cd9920twfctb40000gn/T/ipykernel_54723/949731264.py:3: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
      "/var/folders/m8/k1bt27ks3h3cd9920twfctb40000gn/T/ipykernel_54723/949731264.py:5: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  agent = initialize_agent(\n"
     ]
    }
   ],
   "source": [
    "# Set up the LLM again\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "# Create the agent with your tool\n",
    "agent = initialize_agent(\n",
    "    tools=[qa_tool],\n",
    "    llm=ChatOpenAI(model=\"gpt-3.5-turbo\"),\n",
    "    agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78ed8e8",
   "metadata": {},
   "source": [
    "### Run the Agent for a Sample Question\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ae25ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable(name=\"Eleo_QA_Session\")  # this labels the function for LangSmith\n",
    "def ask_agent_traced(question: str):\n",
    "    ask_agent_traced(\"What does Eleo say about pronunciation?\") # New way with LangSmith tracking\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed47e0fb",
   "metadata": {},
   "source": [
    "### Add Memory to the Agent (ConversationBufferMemory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ccee673",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace61333",
   "metadata": {},
   "source": [
    "### Create Conversational Agent (With Memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78de6e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent, AgentType\n",
    "\n",
    "agent_with_memory = initialize_agent(\n",
    "    tools=[qa_tool],\n",
    "    llm=llm,\n",
    "    agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51bd60db",
   "metadata": {},
   "source": [
    "### Run a Multi-Turn Conversation with Memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5aa792a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m8/k1bt27ks3h3cd9920twfctb40000gn/T/ipykernel_54723/1332888517.py:2: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response_1 = agent_with_memory.run(\"How does Eleo recommend practicing German pronunciation?\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
      "Action: VideoQA\n",
      "Action Input: How does Eleo recommend practicing German pronunciation?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mEleo recommends practicing German pronunciation by engaging in self-talk in the language you are learning. This involves having conversations with yourself in German during daily activities. Additionally, listening to and speaking with native speakers or other German speakers is ideal. If you don't have someone to practice with, watching videos with authentic content, like those on FluentU, can also help improve your pronunciation and vocabulary.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mDo I need to use a tool? No\n",
      "AI: Eleo recommends practicing German pronunciation by engaging in self-talk in the language you are learning, having conversations with yourself in German during daily activities, listening to and speaking with native speakers or other German speakers, and watching videos with authentic content.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Eleo recommends practicing German pronunciation by engaging in self-talk in the language you are learning, having conversations with yourself in German during daily activities, listening to and speaking with native speakers or other German speakers, and watching videos with authentic content.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n",
      "AI: Of course! Eleo recommends practicing German pronunciation by talking to yourself in German, having conversations in German during your daily activities, and listening to native speakers or watching videos in German. It's all about immersing yourself in the language!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Of course! Eleo recommends practicing German pronunciation by talking to yourself in German, having conversations in German during your daily activities, and listening to native speakers or watching videos in German. It's all about immersing yourself in the language!\n"
     ]
    }
   ],
   "source": [
    "# Ask the agent a question\n",
    "response_1 = agent_with_memory.run(\"How does Eleo recommend practicing German pronunciation?\")\n",
    "print(response_1)\n",
    "\n",
    "# Follow-up question\n",
    "response_2 = agent_with_memory.run(\"Can you explain that again more simply?\")\n",
    "print(response_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3014fb8f",
   "metadata": {},
   "source": [
    "### Restricts answers to content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d48dbf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Custom prompt template\n",
    "custom_prompt = PromptTemplate.from_template(\n",
    "    template=\"\"\"\n",
    "You are an assistant that answers questions only using the following transcript chunk.\n",
    "If the answer is not contained within it, reply with \"I don't know.\"\n",
    "\n",
    "Transcript:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011ea5a8",
   "metadata": {},
   "source": [
    "### Create the RetrievalQA with the Custom Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61611426",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=ChatOpenAI(model=\"gpt-3.5-turbo\"),\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs={\"prompt\": custom_prompt},\n",
    "    return_source_documents=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
