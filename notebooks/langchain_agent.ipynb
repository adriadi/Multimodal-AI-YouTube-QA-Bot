{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eac5c4d0",
   "metadata": {},
   "source": [
    "## Import Dependencies and Tools\n",
    "This section loads necessary libraries and adds the utils folder to the import path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "617df7ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adriannadziadyk/Multimodal-AI-YouTube-QA-Bot/notebooks/../agents/langchain_agent.py:27: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  db = FAISS.load_local(vectorstore_path, OpenAIEmbeddings(), allow_dangerous_deserialization=True)\n",
      "/Users/adriannadziadyk/Multimodal-AI-YouTube-QA-Bot/notebooks/../agents/langchain_agent.py:51: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm=ChatOpenAI(model=\"gpt-3.5-turbo\"),\n",
      "/Users/adriannadziadyk/Multimodal-AI-YouTube-QA-Bot/notebooks/../agents/langchain_agent.py:69: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
      "/Users/adriannadziadyk/Multimodal-AI-YouTube-QA-Bot/notebooks/../agents/langchain_agent.py:71: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  agent_with_memory = initialize_agent(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import os\n",
    "\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.tools import Tool\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.document_loaders import TextLoader\n",
    "from utils.whisper import whisper_tool\n",
    "from agents.langchain_agent import agent_with_memory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aecb876",
   "metadata": {},
   "source": [
    "## Load Vectorstore and Build Retriever\n",
    "Load the FAISS vector store to enable transcript-based question answering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5684419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use current working directory since __file__ is not defined in notebooks\n",
    "project_root = os.getcwd()\n",
    "vectorstore_path = os.path.join(project_root, \"../data/vectorstores/eleo_faiss\")\n",
    "\n",
    "db = FAISS.load_local(vectorstore_path, OpenAIEmbeddings(), allow_dangerous_deserialization=True)\n",
    "\n",
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51d900c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for FAISS files in: /Users/adriannadziadyk/Multimodal-AI-YouTube-QA-Bot/data/vectorstores/eleo_faiss\n",
      "Found files: ['index.faiss', 'index.pkl']\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "print(\"Looking for FAISS files in:\", os.path.abspath(vectorstore_path))\n",
    "print(\"Found files:\", os.listdir(vectorstore_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6932ee",
   "metadata": {},
   "source": [
    "## Define Custom Prompt Template\n",
    "Create a custom prompt to ensure the agent only answers using transcript content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "394ef87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "custom_prompt = PromptTemplate.from_template(\n",
    "    template=\"\"\"\n",
    "You are an assistant that answers questions only using the following transcript chunk.\n",
    "If the answer is not contained within it, reply with \"I don't know.\"\n",
    "\n",
    "Transcript:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7b12ca",
   "metadata": {},
   "source": [
    "## Create Retrieval QA Chain\n",
    "Build a chain that uses the retriever and custom prompt for context-aware answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "244edee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=ChatOpenAI(model=\"gpt-3.5-turbo\"),\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs={\"prompt\": custom_prompt},\n",
    "    return_source_documents=False\n",
    ")\n",
    "\n",
    "def answer_question_only_result(query: str) -> str:\n",
    "    return qa_chain.invoke({\"query\": query})[\"result\"]\n",
    "\n",
    "qa_tool = Tool(\n",
    "    name=\"VideoQA\",\n",
    "    func=answer_question_only_result,\n",
    "    description=\"Answers questions about the Eleo German learning video\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93b0dbc",
   "metadata": {},
   "source": [
    "## Initialize Tools and LLM\n",
    "Combine QA and Whisper tools to equip the agent for multimodal tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5d988ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [qa_tool, whisper_tool]\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bb29a4",
   "metadata": {},
   "source": [
    "## ðŸ§ª LangSmith Tracing Setup\n",
    "Define a tracked function for LangSmith monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30e61803",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import traceable\n",
    "\n",
    "@traceable(name=\"Eleo_QA_Session\")\n",
    "def ask_agent_traced(question: str):\n",
    "    return agent_with_memory.run(question)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd8c00c",
   "metadata": {},
   "source": [
    "## ðŸ“Š Run Test Questions\n",
    "Example usage to validate that the system answers accurately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "501a5ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m8/k1bt27ks3h3cd9920twfctb40000gn/T/ipykernel_83249/3644087192.py:5: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  return agent_with_memory.run(question)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
      "Action: VideoQA\n",
      "Action Input: How does Eleo recommend practicing German pronunciation?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mEleo recommends practicing German pronunciation by reading and listening to materials at B1 or B2 level to improve vocabulary.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mDo I need to use a tool? No\n",
      "AI: Eleo recommends practicing German pronunciation by reading and listening to materials at B1 or B2 level to improve vocabulary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Eleo recommends practicing German pronunciation by reading and listening to materials at B1 or B2 level to improve vocabulary.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n",
      "AI: Eleo recommends practicing German pronunciation by reading and listening to materials at a B1 or B2 level to improve your vocabulary. This can help you become more comfortable with German sounds and pronunciation. Practice regularly to see improvement.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Eleo recommends practicing German pronunciation by reading and listening to materials at a B1 or B2 level to improve your vocabulary. This can help you become more comfortable with German sounds and pronunciation. Practice regularly to see improvement.\n"
     ]
    }
   ],
   "source": [
    "response_1 = ask_agent_traced(\"How does Eleo recommend practicing German pronunciation?\")\n",
    "print(response_1)\n",
    "\n",
    "response_2 = ask_agent_traced(\"Can you explain that again more simply?\")\n",
    "print(response_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52efaa7",
   "metadata": {},
   "source": [
    "###  LangChain RetrievalQA setup\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ffe80a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agent initialisation code\n",
    "agent_executor = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae552a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n",
      "AI: \"Guten Tag\" is a German greeting that means \"Good day\" or \"Good afternoon.\" It is a common way to say hello in German.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\"Guten Tag\" is a German greeting that means \"Good day\" or \"Good afternoon.\" It is a common way to say hello in German.\n"
     ]
    }
   ],
   "source": [
    "response = agent_executor.run(\"What does 'Guten Tag' mean?\")\n",
    "print(response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
